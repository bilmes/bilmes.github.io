<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en-US" xml:lang="en-US"><head><title>Jeff A. Bilmes Homepage</title><meta http-equiv="Content-Type" content="text/html; charset=ISO-8859-1"></meta><meta name="Keywords" content="Jeff Bilmes, Bilmes"></meta><meta name="Description" content="Jeff Bilmes's Home Page."></meta><link rel="stylesheet" href="../bilmes_style.css" type="text/css"></link></head><body><div class="container"><div class="navigation"><ul class="navbar"><li><a href="index.html">Home</a></li><li><a href="about.html">About</a></li><li><a href="prospective.html">Prospective Students</a></li><li><a href="teaching.html">Teaching</a></li><li><a href="research.html">Research</a></li><li><a href="people.html">People</a></li><li><a href="sort_date.html">Publications</a></li><li><a href="software.html">Software 
                              &amp;†Data</a></li><li><a href="talks.html">Talks</a></li></ul></div><div class="content"><div id="toptitle"><h1><a href="index.html">Jeff A. Bilmes</a>'s Publications</h1></div><p xmlns=""><big>&#8226;
  <a href="sort_date.html">Sorted by Date</a> &#8226;
  <a href="class_type.html">Classified by Publication Type</a> &#8226;
  <a href="class_rescat.html">Classified by Research Category</a> &#8226;
  <a href="sort_author.html">Sorted by First Author Last Name</a> &#8226;
  <a href="class_author.html">Classified by Author Last Name</a> &#8226;
  </big></p>
<h2><b> SVitchboard-II and FiSVer-I: Crafting high quality and low complexity conversational english speech corpora using submodular function optimization</b></h2><p class="citation"> Yuzong Liu,  Rishabh Iyer,  Katrin Kirchhoff, and <a href="http://melodi.ee.washington.edu/~bilmes"> Jeff Bilmes</a>. <b> SVitchboard-II and FiSVer-I: Crafting high quality and low complexity conversational english speech corpora using submodular function optimization</b>. <i> Computer Speech & Language</i>,  42:122&ndash;142, 2017.</p><h3>Download</h3><p><a xmlns="" href="../mypubs/liu-svitchboard-fisver-submodular-2017.pdf">[PDF]846.7kB
  </a>&nbsp;<a xmlns="" href="http://dx.doi.org/https://doi.org/10.1016/j.csl.2016.10.002">[gzipped postscript]</a>&nbsp;<a xmlns="" href="http://dx.doi.org/https://doi.org/10.1016/j.csl.2016.10.002">[postscript]</a>&nbsp;<a xmlns="" href="http://dx.doi.org/https://doi.org/10.1016/j.csl.2016.10.002">[HTML]</a>&nbsp;</p><h3>Abstract</h3><p class="abstract"> We introduce a set of benchmark corpora of conversational English speech derived from the Switchboard-I and Fisher datasets. Traditional automatic speech recognition (ASR) research requires considerable computational resources and has slow experimental turnaround times. Our goal is to introduce these new datasets to researchers in the ASR and machine learning communities in order to facilitate the development of novel speech recognition techniques on smaller but still acoustically rich, diverse, and hence interesting corpora. We select these corpora to maximize an acoustic quality criterion while limiting the vocabulary size (from 10 words up to 10,000 words), where both ‚Äúacoustic quality‚Äù and vocabulary size are adeptly measured via various submodular functions. We also survey numerous submodular functions that could be useful to measure both ‚Äúacoustic quality‚Äù and ‚Äúcorpus complexity‚Äù and offer guidelines on when and why a scientist may wish use to one vs. another. The corpora selection process itself is naturally performed using various state-of-the-art submodular function optimization procedures, including submodular level-set constrained submodular optimization (SCSC/SCSK), difference-of-submodular (DS) optimization, and unconstrained submodular minimization (SFM), all of which are fully defined herein. While the focus of this paper is on the resultant speech corpora, and the survey of possible objectives, a consequence of the paper is a thorough empirical comparison of the relative merits of these modern submodular optimization procedures. We provide baseline word recognition results on all of the resultant speech corpora for both Gaussian mixture model (GMM) and deep neural network (DNN)-based systems, and we have released all of the corpora definitions and Kaldi training recipes for free in the public domain.</p><a href="liu-svitchboard-fisver-submodular-2017.bib"><h3>BibTeX</h3></a><pre>@article{liu-svitchboard-fisver-submodular-2017,
title = {SVitchboard-II and FiSVer-I: Crafting high quality and low complexity conversational english speech corpora using submodular function optimization},
journal = {Computer Speech &amp; Language},
volume = {42},
pages = {122-142},
year = {2017},
issn = {0885-2308},
doi = {https://doi.org/10.1016/j.csl.2016.10.002},
url = {https://www.sciencedirect.com/science/article/pii/S0885230816301942},
author = {Yuzong Liu and Rishabh Iyer and Katrin Kirchhoff and Jeff Bilmes},
keywords = {Submodular function optimization, Automatic speech recognition, Speech corpus},
abstract = {We introduce a set of benchmark corpora of conversational English speech derived from the Switchboard-I and Fisher datasets. Traditional automatic speech recognition (ASR) research requires considerable computational resources and has slow experimental turnaround times. Our goal is to introduce these new datasets to researchers in the ASR and machine learning communities in order to facilitate the development of novel speech recognition techniques on smaller but still acoustically rich, diverse, and hence interesting corpora. We select these corpora to maximize an acoustic quality criterion while limiting the vocabulary size (from 10 words up to 10,000 words), where both ‚Äúacoustic quality‚Äù and vocabulary size are adeptly measured via various submodular functions. We also survey numerous submodular functions that could be useful to measure both ‚Äúacoustic quality‚Äù and ‚Äúcorpus complexity‚Äù and offer guidelines on when and why a scientist may wish use to one vs. another. The corpora selection process itself is naturally performed using various state-of-the-art submodular function optimization procedures, including submodular level-set constrained submodular optimization (SCSC/SCSK), difference-of-submodular (DS) optimization, and unconstrained submodular minimization (SFM), all of which are fully defined herein. While the focus of this paper is on the resultant speech corpora, and the survey of possible objectives, a consequence of the paper is a thorough empirical comparison of the relative merits of these modern submodular optimization procedures. We provide baseline word recognition results on all of the resultant speech corpora for both Gaussian mixture model (GMM) and deep neural network (DNN)-based systems, and we have released all of the corpora definitions and Kaldi training recipes for free in the public domain.},
}
</pre><h3>Share</h3><p class="share"><div class="addthis_toolbox addthis_default_style addthis_32x32_style"><a class="addthis_button_preferred_1"></a><a class="addthis_button_preferred_2"></a><a class="addthis_button_preferred_3"></a><a class="addthis_button_preferred_4"></a><a class="addthis_button_compact"></a></div><script type="text/javascript" src="http://s7.addthis.com/js/250/addthis_widget.js#pubid=xa-4e39e6cc4ff7d9d9"></script></p><hr width="100%" size="2"></hr><p><small>
 Generated by
 <a xmlns="" href="https://sourceforge.net/projects/bib2html/">bib2html.pl</a>
 (written by <a xmlns="" href="http://sourceforge.net/users/patstg/">Patrick Riley</a>
  ) on
  Sun Oct 01, 2023 14:42:07</small></p></div><div class="footer"><a class="right_pad" href="index.html">
Go home</a><a class="right_pad" href="http://mailhide.recaptcha.net/d?k=01l3ho3qEvdj--sJ6OJ8LS1A==&amp;c=7CXXfzP4KrBHZwLeD1xbEluzWyfYR5lzjGozsG53sBw=" onclick="window.open('http://mailhide.recaptcha.net/d?k=01l3ho3qEvdj--sJ6OJ8LS1A==&amp;c=7CXXfzP4KrBHZwLeD1xbEluzWyfYR5lzjGozsG53sBw=', '', 'toolbar=0,scrollbars=0,location=0,statusbar=0,menubar=0,resizable=0,width=500,height=300'); return false;" title="Reveal this e-mail address">Email me</a> Last updated Wed Jun 07 01:03 PDT 2023
 

</div></div></body></html>
